{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNajy7NcYoYVcdakBmA6y+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kilos11/Beyond-the-Basic-Stuff-with-Python/blob/main/9_MEASURING_PERFORMANCE_AND_BIG_O_ALGORITHM_ANALYSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The timeit Module**#\n",
        "##“Premature optimization is the root of all evil” is a common saying in software development. (It’s often attributed to computer scientist Donald Knuth, who attributes it to computer scientist Tony Hoare. Tony Hoare, in turn, attributes it to Donald Knuth.) Premature optimization, or optimizing before knowing what needs to be optimized, often manifests itself when programmers try to use clever tricks to save memory or write faster code. For example, one of these tricks is using the XOR algorithm to swap two integer values without using a third, temporary variable:"
      ],
      "metadata": {
        "id": "JzugR1PreupU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = 42, 101  # Set up the two variables.\n",
        "print(a, b)\n",
        "# A series of ^ XOR operations will end up swapping their values:\n",
        "a = a ^ b\n",
        "b = a ^ b\n",
        "a = a ^ b\n",
        "\n",
        "print(a, b)  # The values are now swapped.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UpyQaAOe7ih",
        "outputId": "69a23cca-b0dc-4705-fd37-8c87461945c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 101\n",
            "101 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unless you’re unfamiliar with the XOR algorithm (which uses the ^ bitwise operator), this code looks cryptic. The problem with using clever programming tricks is that they can produce complicated, unreadable code. Recall that one of the Zen of Python tenets is readability counts.\n",
        "\n",
        "##Even worse, your clever trick might turn out not to be so clever. You can’t just assume a crafty trick is faster or that the old code it’s replacing was even all that slow to begin with. The only way to find out is by measuring and comparing the runtime: the amount of time it takes to run a program or piece of code. Keep in mind that increasing the runtime means the program is slowing down: the program is taking more time to do the same amount of work. (We also sometimes use the term runtime to refer to the period during which the program is running. This error happened at runtime means the error happened while the program was running as opposed to when the program was being compiled into bytecode.)\n",
        "\n",
        "##The Python standard library’s timeit module can measure the runtime speed of a small snippet of code by running it thousands or millions of times, letting you determine an average runtime. The timeit module also temporarily disables the automatic garbage collector to ensure more consistent runtimes. If you want to test multiple lines, you can pass a multiline code string or separate the code lines using semicolons:"
      ],
      "metadata": {
        "id": "KbZA-P8AgL6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timeit.timeit('a, b = 42, 101; a = a ^ b; b = a ^ b; a = a ^ b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Dzc-dWgZHs",
        "outputId": "5e757f66-d9a1-4622-f5da-221549c34324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20374666200001457"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**The cProfile Profiler**#\n",
        "##Although the timeit module is useful for measuring small code snippets, the cProfile module is more effective for analyzing entire functions or programs. Profiling analyzes your program’s speed, memory usage, and other aspects systematically. The cProfile module is Python’s profiler, or software that can measure a program’s runtime as well as build a profile of runtimes for the program’s individual function calls. This information provides substantially more granular measurements of your code.\n",
        "\n",
        "##To use the cProfile profiler, pass a string of the code you want to measure to cProfile.run(). Let’s look at how cProfiler measures and reports the execution of a short function that sums all the numbers from 1 to 1,000,000:"
      ],
      "metadata": {
        "id": "k44ChP8hhK_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, cProfile\n",
        "\n",
        "def addNumbers():\n",
        "    total = 0\n",
        "    for i in range(1,1000001):\n",
        "        total += 1\n",
        "\n",
        "cProfile.run(\"addNumbers()\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3_fDkvShgxl",
        "outputId": "250ae86e-dbec-4893-fb6b-45a56583a1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         4 function calls in 0.086 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        1    0.086    0.086    0.086    0.086 <ipython-input-3-71dba91806f2>:3(addNumbers)\n",
            "        1    0.000    0.000    0.086    0.086 <string>:1(<module>)\n",
            "        1    0.000    0.000    0.086    0.086 {built-in method builtins.exec}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Each line represents a different function and the amount of time spent in that function. The columns in cProfile.run()’s output are:\n",
        "\n",
        "##*ncalls  The number of calls made to the function*\n",
        "##*tottime  The total time spent in the function, excluding time in subfunctions*\n",
        "##*percall  The total time divided by the number of calls*\n",
        "##*cumtime  The cumulative time spent in the function and all subfunctions*\n",
        "##*percall  The cumulative time divided by the number of calls*\n",
        "##*filename:lineno(function)  The file the function is in and at which line number*\n",
        "##For example, download the rsaCipher.py and al_sweigart_pubkey.txt files from https://nostarch.com/crackingcodes/. This RSA Cipher program was featured in Cracking Codes with Python (No Starch Press, 2018). Enter the following into the interactive shell to profile the encryptAndWriteToFile() function as it encrypts a 300,000-character message created by the 'abc' * 100000 expression:"
      ],
      "metadata": {
        "id": "irUfHk0XixYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile, rsaCipher\n",
        "\n",
        "cProfile.run(\"rsaCipher.encryptAndWriteToFile('encrypted_file.txt', 'al_sweigart_pubkey.txt', 'abc'*100000)\")\n"
      ],
      "metadata": {
        "id": "815PWoQJkDkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Big O Algorithm Analysis**#\n",
        "##Big O is a form of algorithm analysis that describes how code will scale. It classifies the code into one of several orders that describes, in general terms, how much longer the code’s runtime will take as the amount of work it has to do increases. Python developer Ned Batchelder describes big O as an analysis of “how code slows as data grows,” which is also the title of his informative PyCon 2018 talk, which is available at https://youtu.be/duvZ-2UK0fc/.\n",
        "\n",
        "##Let’s consider the following scenario. Say you have a certain amount of work that takes an hour to complete. If the workload doubles, how long would it take then? You might be tempted to think it takes twice as long, but actually, the answer depends on the kind of work that’s being done.\n",
        "\n",
        "##If it takes an hour to read a short book, it will take more or less two hours to read two short books. But if you can alphabetize 500 books in an hour, alphabetizing 1,000 books will most likely take longer than two hours, because you have to find the correct place for each book in a much larger collection of books. On the other hand, if you’re just checking whether or not a bookshelf is empty, it doesn’t matter if there are 0, 10, or 1,000 books on the shelf. One glance and you’ll immediately know the answer. The runtime remains roughly constant no matter how many books there are. Although some people might be faster or slower at reading or alphabetizing books, these general trends remain the same.\n",
        "\n",
        "##The big O of the algorithm describes these trends. An algorithm can run on a fast or slow computer, but we can still use big O to describe how well an algorithm performs in general, regardless of the actual hardware executing the algorithm. Big O doesn’t use specific units, such as seconds or CPU cycles, to describe an algorithm’s runtime, because these would vary between different computers or programming languages."
      ],
      "metadata": {
        "id": "TMscjRQvmDyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Big O Orders**#\n",
        "##Big O notation commonly defines the following orders. These range from the lower orders, which describe code that, as the amount of data grows, slows down the least, to the higher orders, which describe code that slows down the most:\n",
        "\n",
        "##*O(1), Constant Time (the lowest order)*\n",
        "##*O(log n), Logarithmic Time*\n",
        "##*O(n), Linear Time*\n",
        "##*O(n log n), N-Log-N Time*\n",
        "##*O(n2), Polynomial Time*\n",
        "##*O(2n), Exponential Time*\n",
        "##*O(n!), Factorial Time (the highest order)*\n",
        "##Notice that big O uses the following notation: a capital O, followed by a pair of parentheses containing a description of the order. The capital O represents ORDER or ON THE ORDER OF. The n represents the size of the input data the code will work on. We pronounce O(n) as “big oh of n” or “big oh n.”\n",
        "\n",
        "##You don’t need to understand the precise mathematic meanings of words like LOGARITHMIC or POLYNOMIAL to use big O notation. I’ll describe each of these orders in detail in the next section, but here’s an oversimplified explanation of them:\n",
        "\n",
        "##*O(1) and O(log n) algorithms are fast.*\n",
        "##*O(n) and O(n log n) algorithms aren’t bad.*\n",
        "##*O(n2), O(2n), and O(n!) algorithms are slow.*\n",
        "##Certainly, you could find counterexamples, but these descriptions are good rules in general. There are more big O orders than the ones listed here, but these are the most common. Let’s look at the kinds of tasks that each of these orders describes."
      ],
      "metadata": {
        "id": "5RlqhkxAmlXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**A Bookshelf Metaphor for Big O Orders**#\n",
        "##In the following big O order examples, I’ll continue using the bookshelf metaphor. The n refers to the number of books on the bookshelf, and the big O ordering describes how the various tasks take longer as the number of books increases.\n",
        "\n",
        "##**O(1), Constant Time**##\n",
        "##Finding out “Is the bookshelf empty?” is a constant time operation. It doesn’t matter how many books are on the shelf; one glance tells us whether or not the bookshelf is empty. The number of books can vary, but the runtime remains constant, because as soon as we see one book on the shelf, we can stop looking. The n value is irrelevant to the speed of the task, which is why there is no n in O(1). You might also see constant time written as O(c).\n",
        "\n",
        "##**O(log n), Logarithmic**##\n",
        "##Logarithms are the inverse of exponentiation: the exponent 24, or 2 × 2 × 2 × 2, equals 16, whereas the logarithm log2(16) (pronounced “log base 2 of 16”) equals 4. In programming, we often assume base 2 to be the logarithm base, which is why we write O(log n) instead of O(log2 n).\n",
        "\n",
        "##Searching for a book on an alphabetized bookshelf is a logarithmic time operation. To find one book, you can check the book in the middle of the shelf. If that is the book you’re searching for, you’re done. Otherwise, you can determine whether the book you’re searching for comes before or after this middle book. By doing so, you’ve effectively reduced the range of books you need to search in half. You can repeat this process again, checking the middle book in the half that you expect to find it. We call this the binary search algorithm, and there’s an example of it in “Big O Analysis Examples” later in this chapter.\n",
        "\n",
        "##The number of times you can split a set of n books in half is log2 n. On a shelf of 16 books, it will take at most four steps to find the right one. Because each step reduces the number of books you need to search by one half, a bookshelf with double the number of books takes just one more step to search. If there were 4.2 billion books on the alphabetized bookshelf, it would still only take 32 steps to find a particular book.\n",
        "\n",
        "##Log n algorithms usually involve a divide and conquer step, which selects half of the n input to work on and then another half from that half, and so on. Log n operations scale nicely: the workload n can double in size, but the runtime increases by only one step.\n",
        "\n",
        "##**O(n), Linear Time**##\n",
        "##Reading all the books on a bookshelf is a linear time operation. If the books are roughly the same length and you double the number of books on the shelf, it will take roughly double the amount of time to read all the books. The runtime increases in proportion to the number of books n.\n",
        "\n",
        "##**O(n log n), N-Log-N Time**##\n",
        "##Sorting a set of books into alphabetical order is an n-log-n time operation. This order is the runtime of O(n) and O(log n) multiplied together. You can think of a O(n log n) task as a O(log n) task that must be performed n times. Here’s a casual description of why.\n",
        "\n",
        "##Start with a stack of books to alphabetize and an empty bookshelf. Follow the steps for a binary search algorithm, as detailed in “O(log n), Logarithmic” on page 232, to find where a single book belongs on the shelf. This is an O(log n) operation. With n books to alphabetize, and each book taking log n steps to alphabetize, it takes n × log n, or n log n, steps to alphabetize the entire set of books. Given twice as many books, it takes a bit more than twice as long to alphabetize all of them, so n log n algorithms scale fairly well.\n",
        "\n",
        "##In fact, all of the efficient general sorting algorithms are O(n log n): merge sort, quicksort, heapsort, and Timsort. (Timsort, invented by Tim Peters, is the algorithm that Python’s sort() method uses.)\n",
        "\n",
        "##**O(n2), Polynomial Time**##\n",
        "##Checking for duplicate books on an unsorted bookshelf is a polynomial time operation. If there are 100 books, you could start with the first book and compare it with the 99 other books to see whether they’re the same. Then you take the second book and check whether it’s the same as any of the 99 other books. Checking for a duplicate of a single book is 99 steps (we’ll round this up to 100, which is our n in this example). We have to do this 100 times, once for each book. So the number of steps to check for any duplicate books on the bookshelf is roughly n × n, or n2. (This approximation to n2 still holds even if we were clever enough not to repeat comparisons.)\n",
        "\n",
        "##The runtime increases by the increase in books squared. Checking 100 books for duplicates is 100 × 100, or 10,000 steps. But checking twice that amount, 200 books, is 200 × 200, or 40,000 steps: four times as much work.\n",
        "\n",
        "##In my experience writing code in the real world, I’ve found the most common use of big O analysis is to avoid accidentally writing an O(n2) algorithm when an O(n log n) or O(n) algorithm exists. The O(n2) order is when algorithms dramatically slow down, so recognizing your code as O(n2) or higher should give you pause. Perhaps there’s a different algorithm that can solve the problem faster. In these cases, taking a data structure and algorithms (DSA) course, whether at a university or online, can be helpful.\n",
        "\n",
        "##We also call O(n2) quadratic time. Algorithms could have O(n3), or cubic time, which is slower than O(n2); O(n4), or quartic time, which is slower than O(n3); or other polynomial time complexities.\n",
        "\n",
        "##**O(2n), Exponential Time**##\n",
        "##Taking photos of the shelf with every possible combination of books on it is an exponential time operation. Think of it this way: each book on the shelf can either in be included in the photo or not included. Figure 13-1 shows every combination where n is 1, 2, or 3. If n is 1, there are two possible photos: with the book and without. If n is 2, there are four possible photos: both books on the shelf, both books off, the first on and second off, and the second on and first off. When you add a third book, you’ve once again doubled the amount of work you have to do: you need to do every subset of two books that includes the third book (four photos) and every subset of two books that excludes the third book (another four photos, for 23 or eight photos). Each additional book doubles the workload. For n books, the number of photos you need to take (that is, the amount of work you need to do) is 2n.\n",
        "\n",
        "##The runtime for exponential tasks increases very quickly. Six books require 26 or 32 photos, but 32 books would include 232 or more than 4.2 billion photos. O(2n), O(3n), O(4n), and so on are different orders but all have exponential time complexity.\n",
        "\n",
        "##**O(n!), Factorial Time**##\n",
        "##Taking a photo of the books on the shelf in every conceivable order is a factorial time operation. We call every possible order the permutation of n books. This results in n!, or n factorial, orderings. The factorial of a number is the multiplication product of all positive integers up to the number. For example, 3! is 3 × 2 × 1, or 6. Figure 13-2 shows every possible permutation of three books."
      ],
      "metadata": {
        "id": "pxN0JJfYoORb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Determining the Big O Order of Your Code**#\n",
        "##To determine the big O order for a piece of code, we must do four tasks: identify what the n is, count the steps in the code, drop the lower orders, and drop the coefficients.\n",
        "\n",
        "##For example, let’s find the big O of the following readingList() function:"
      ],
      "metadata": {
        "id": "q8DuA6DYv4ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readingList(books):\n",
        "    numberOfBooks = 0\n",
        "    print('Here are the books I will read:')\n",
        "    for booke in books:\n",
        "        print(book)\n",
        "        numberOfBooks += 1\n",
        "    print(numberOfBooks, 'books total.')"
      ],
      "metadata": {
        "id": "dK5jlPTXwEjM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recall that the n represents the size of the input data that the code works on. In functions, the n is almost always based on a parameter. The readingList() function’s only parameter is books, so the size of books seems like a good candidate for n, because the larger books is, the longer the function takes to run.\n",
        "\n",
        "##Next, let’s count the steps in this code. What counts as a STEP is somewhat vague, but a line of code is a good rule to follow. Loops will have as many steps as the number of iterations multiplied by the lines of code in the loop. To see what I mean, here are the counts for the code inside the readingList() function:"
      ],
      "metadata": {
        "id": "xC-TNQ_6w8zg"
      }
    }
  ]
}